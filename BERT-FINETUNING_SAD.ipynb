{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have your own data for fine-tuning\n",
        "# Example: sequences and labels\n",
        "\n",
        "labels = [0, 1, ...]  # Assuming binary classification, modify accordingly\n",
        "\n"
      ],
      "metadata": {
        "id": "z_7REhGQJZWk"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "MRJ1VWMcLmbL"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train.csv\")"
      ],
      "metadata": {
        "id": "4Y_jHVzMLqDl"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "yozhJXqRL2b4",
        "outputId": "de7035e8-8c4c-4a89-c4a5-e080219bcb0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                post  \\\n",
            "0  Post: my recent stress has come from school. i...   \n",
            "1  Post: i have been stressed about finding a way...   \n",
            "2  Post: i have been stressed out by my daughter ...   \n",
            "3  Post: People talking shit about my friends ups...   \n",
            "4  Post: i am not sure how i feel about my new jo...   \n",
            "\n",
            "                                          question  \\\n",
            "0   Question: This post shows the stress cause of    \n",
            "1   Question: This post shows the stress cause of    \n",
            "2   Question: This post shows the stress cause of    \n",
            "3   Question: This post shows the stress cause of    \n",
            "4   Question: This post shows the stress cause of    \n",
            "\n",
            "                                            response  \n",
            "0  school. Reasoning: The post explicitly mention...  \n",
            "1  financial problem. Reasoning: The post mention...  \n",
            "2  family issues. Reasoning: The post mentions th...  \n",
            "3  social relationships. Reasoning: The post expl...  \n",
            "4  work. Reasoning: The post mentions the poster'...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['response'] = df['response'].str.replace('Reasoning: ', '')\n",
        "\n",
        "# Print the modified DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "hEA1wugCLwBe",
        "outputId": "f2c14d8a-1218-4b77-e827-0fac63d6dc93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   post  \\\n",
            "0     Post: my recent stress has come from school. i...   \n",
            "1     Post: i have been stressed about finding a way...   \n",
            "2     Post: i have been stressed out by my daughter ...   \n",
            "3     Post: People talking shit about my friends ups...   \n",
            "4     Post: i am not sure how i feel about my new jo...   \n",
            "...                                                 ...   \n",
            "5542  Post: i haven't been happy with us, and its on...   \n",
            "5543               Post: Stress has made me irrational.   \n",
            "5544  Post: im so stressed out, i just dont have tim...   \n",
            "5545             Post: my friends wont be there for me.   \n",
            "5546  Post: The face I heard before Your head trip's...   \n",
            "\n",
            "                                             question  \\\n",
            "0      Question: This post shows the stress cause of    \n",
            "1      Question: This post shows the stress cause of    \n",
            "2      Question: This post shows the stress cause of    \n",
            "3      Question: This post shows the stress cause of    \n",
            "4      Question: This post shows the stress cause of    \n",
            "...                                               ...   \n",
            "5542   Question: This post shows the stress cause of    \n",
            "5543   Question: This post shows the stress cause of    \n",
            "5544   Question: This post shows the stress cause of    \n",
            "5545   Question: This post shows the stress cause of    \n",
            "5546   Question: This post shows the stress cause of    \n",
            "\n",
            "                                               response  \n",
            "0     school. The post explicitly mentions that the ...  \n",
            "1     financial problem. The post mentions being str...  \n",
            "2     family issues. The post mentions that the post...  \n",
            "3     social relationships. The post explicitly ment...  \n",
            "4     work. The post mentions the poster's uncertain...  \n",
            "...                                                 ...  \n",
            "5542  emotional turmoil. The post mentions that the ...  \n",
            "5543  emotional turmoil. The post explicitly states ...  \n",
            "5544  everyday decision making. The post mentions be...  \n",
            "5545  social relationships. The post explicitly ment...  \n",
            "5546  other causes. The post does not provide any sp...  \n",
            "\n",
            "[5547 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func(output_an):\n",
        "    \"\"\"\n",
        "    Maps the content of 'output_an' to a numerical label based on specific keywords.\n",
        "\n",
        "    Parameters:\n",
        "    - output_an (str): The input string to be classified.\n",
        "\n",
        "    Returns:\n",
        "    - int: Numerical label corresponding to the category.\n",
        "    \"\"\"\n",
        "    output_lower = output_an.lower()\n",
        "\n",
        "    if 'school' in output_lower:\n",
        "        return 0\n",
        "    elif 'financial' in output_lower:\n",
        "        return 1\n",
        "    elif 'family' in output_lower:\n",
        "        return 2\n",
        "    elif 'social' in output_lower:\n",
        "        return 3\n",
        "    elif 'work' in output_lower:\n",
        "        return 4\n",
        "    elif 'health' in output_lower:\n",
        "        return 5\n",
        "    elif 'emotional' in output_lower:\n",
        "        return 6\n",
        "    elif 'decision' in output_lower:\n",
        "        return 7\n",
        "    elif 'other' in output_lower:\n",
        "        return 8\n",
        "    else:\n",
        "        return -1  # or any other value to indicate no match\n",
        "\n",
        "# Example usage:\n",
        "\n"
      ],
      "metadata": {
        "id": "nOZTuH4qM4GF"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = df['response'].to_list()\n"
      ],
      "metadata": {
        "id": "sCjLrapRMYkU"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[]"
      ],
      "metadata": {
        "id": "36_A6534M7d_"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sequences:\n",
        "  labels.append(func(i))"
      ],
      "metadata": {
        "id": "gSJPgueYM_BN"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Example usage\n",
        "model = BertForSequenceClassification(num_classes=9)\n"
      ],
      "metadata": {
        "id": "8svKwx1LNQFQ"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input sequences\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenized_inputs = tokenizer(sequences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Create PyTorch dataset\n",
        "dataset = TensorDataset(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'], tokenized_inputs['token_type_ids'], torch.tensor(labels))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader for training and validation sets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Instantiate the model\n",
        "\n",
        "# Set up optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "total_steps = len(train_dataloader) * 3  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        input_ids, attention_mask, token_type_ids, labels = batch\n",
        "        input_ids, attention_mask, token_type_ids, labels = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_loss}\")\n",
        "\n",
        "# Validation loop\n",
        "model.eval()\n",
        "val_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_dataloader:\n",
        "        input_ids, attention_mask, token_type_ids, labels = batch\n",
        "        input_ids, attention_mask, token_type_ids, labels = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "avg_val_loss = val_loss / len(val_dataloader)\n",
        "val_accuracy = correct / total\n",
        "\n",
        "print(f\"Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}\")\n"
      ],
      "metadata": {
        "id": "MPut1t0KJWL_",
        "outputId": "6e70cc1f-20e6-4b4b-b63d-645aab3291ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Training Loss: 0.3694627137432585\n",
            "Epoch 2/3, Training Loss: 0.031169368021136564\n",
            "Epoch 3/3, Training Loss: 0.019980016995301778\n",
            "Validation Loss: 0.014200728725908059, Validation Accuracy: 0.9981981981981982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.read_csv('/content/val.csv')  # Replace '/content/val.csv' with the actual path\n"
      ],
      "metadata": {
        "id": "Bk_uc7oHPI15"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df['response'] = val_df['response'].str.replace('Reasoning: ', '')\n",
        "\n",
        "# Print the modified DataFrame\n",
        "print(val_df)"
      ],
      "metadata": {
        "id": "Lmb7LpscPO0F",
        "outputId": "129ef101-5a1d-4512-93fb-277d80236f32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  post  \\\n",
            "0    Post: the bad thing is that i have to go to sc...   \n",
            "1    Post: anyways i am so sick of the constant dra...   \n",
            "2    Post: My baby is sick and I feel bad that he i...   \n",
            "3    Post: I always feel guilty when my family star...   \n",
            "4    Post: Its made my relationships with people ve...   \n",
            "..                                                 ...   \n",
            "611  Post: I get the feeling that no matter where I...   \n",
            "612  Post: I'm having a hard time getting a job. Th...   \n",
            "613  Post: What and how am I going to do? Seriously...   \n",
            "614           Post: I am very worried about my mother.   \n",
            "615  Post: my job. it has 0 application for the shi...   \n",
            "\n",
            "                                            question  \\\n",
            "0     Question: This post shows the stress cause of    \n",
            "1     Question: This post shows the stress cause of    \n",
            "2     Question: This post shows the stress cause of    \n",
            "3     Question: This post shows the stress cause of    \n",
            "4     Question: This post shows the stress cause of    \n",
            "..                                               ...   \n",
            "611   Question: This post shows the stress cause of    \n",
            "612   Question: This post shows the stress cause of    \n",
            "613   Question: This post shows the stress cause of    \n",
            "614   Question: This post shows the stress cause of    \n",
            "615   Question: This post shows the stress cause of    \n",
            "\n",
            "                                              response  \n",
            "0    school. The post mentions that the poster has ...  \n",
            "1    social relationships. The post mentions being ...  \n",
            "2    health issues. The post mentions that the post...  \n",
            "3    family issues. The post explicitly mentions th...  \n",
            "4    social relationships. The post explicitly ment...  \n",
            "..                                                 ...  \n",
            "611  everyday decision making. The post mentions th...  \n",
            "612  work. The post explicitly mentions that the po...  \n",
            "613  everyday decision making. The post mentions th...  \n",
            "614  family issues. The post explicitly mentions be...  \n",
            "615  work. The post explicitly mentions the job as ...  \n",
            "\n",
            "[616 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = val_df['response'].to_list()\n",
        "labels=[]\n",
        "for i in sequences:\n",
        "    labels.append(func(i))"
      ],
      "metadata": {
        "id": "i42lY41RPXFu"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the validation dataset\n",
        "  # Replace with the actual path to your validation dataset\n",
        "df_val = val_df\n",
        "\n",
        "# Load the fine-tuned model\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Tokenize the validation data\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_data(data, max_length=128):\n",
        "    inputs = tokenizer(\n",
        "        data,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "X_val = tokenize_data(df_val['response'].values.tolist())\n",
        "\n",
        "# Prepare DataLoader\n",
        "val_dataset = TensorDataset(X_val['input_ids'], X_val['attention_mask'], X_val['token_type_ids'])\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        inputs = {'input_ids': batch[0].to(device),\n",
        "                  'attention_mask': batch[1].to(device),\n",
        "                  'token_type_ids': batch[2].to(device)}\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=-1)\n",
        "        predictions = torch.argmax(probabilities, dim=1)\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "# Map predictions to labels\n",
        "print(all_predictions)\n",
        "print(labels)\n",
        "# Map true labels to numerical values using the map_output_label function\n",
        "true_labels = labels\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(true_labels, all_predictions))\n"
      ],
      "metadata": {
        "id": "5LiK9HeFJXou",
        "outputId": "964e64fb-ee00-43d8-b321-71f6ae5415e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 3, 5, 2, 3, 1, 1, 1, 4, 3, 3, 2, 7, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 3, 4, 4, 1, 0, 4, 3, 2, 4, 4, 1, 0, 4, 3, 8, 4, 2, 4, 0, 1, 6, 2, 1, 0, 2, 3, 5, 7, 0, 1, 5, 4, 0, 1, 7, 4, 6, 4, 2, 2, 4, 0, 2, 2, 2, 4, 0, 4, 3, 4, 5, 3, 3, 0, 4, 0, 5, 4, 8, 6, 3, 0, 1, 0, 8, 1, 0, 3, 1, 5, 0, 3, 8, 0, 4, 4, 5, 1, 7, 1, 0, 3, 8, 4, 5, 5, 0, 0, 2, 7, 6, 0, 0, 6, 2, 0, 6, 0, 0, 2, 4, 4, 7, 0, 0, 4, 2, 5, 4, 5, 0, 6, 0, 1, 1, 2, 0, 7, 3, 2, 3, 2, 8, 1, 1, 1, 3, 1, 0, 0, 4, 5, 7, 0, 4, 0, 0, 0, 2, 1, 3, 2, 0, 0, 3, 4, 0, 3, 0, 1, 3, 6, 0, 4, 5, 3, 0, 1, 6, 4, 4, 3, 3, 0, 3, 4, 3, 5, 2, 3, 4, 4, 1, 8, 1, 5, 1, 4, 1, 0, 2, 1, 2, 2, 2, 5, 1, 1, 4, 4, 7, 1, 2, 0, 2, 7, 6, 3, 0, 0, 1, 7, 2, 7, 1, 4, 4, 5, 6, 4, 1, 6, 3, 2, 1, 4, 1, 0, 3, 2, 0, 4, 4, 1, 0, 0, 1, 4, 1, 0, 4, 0, 0, 1, 6, 2, 0, 4, 3, 0, 1, 4, 4, 4, 0, 0, 0, 0, 5, 4, 5, 0, 5, 5, 4, 0, 2, 2, 4, 1, 4, 1, 0, 1, 6, 3, 3, 3, 0, 1, 1, 4, 3, 0, 0, 5, 8, 1, 4, 1, 2, 1, 3, 1, 7, 5, 0, 2, 0, 3, 4, 2, 1, 1, 7, 4, 3, 7, 1, 0, 0, 6, 8, 7, 2, 4, 4, 1, 2, 5, 6, 3, 0, 0, 6, 1, 2, 0, 2, 4, 1, 2, 2, 2, 4, 1, 0, 1, 2, 4, 5, 8, 2, 0, 1, 1, 6, 0, 5, 0, 0, 3, 0, 0, 5, 4, 0, 5, 1, 2, 4, 0, 0, 5, 2, 0, 3, 0, 4, 1, 2, 4, 0, 5, 2, 2, 1, 1, 3, 1, 4, 0, 7, 5, 2, 3, 2, 1, 0, 0, 0, 4, 1, 0, 1, 4, 0, 2, 0, 0, 0, 1, 1, 4, 5, 4, 1, 1, 6, 2, 2, 4, 0, 2, 4, 4, 2, 0, 7, 0, 5, 0, 4, 2, 0, 6, 0, 0, 0, 4, 3, 2, 3, 2, 3, 4, 4, 8, 5, 2, 3, 4, 1, 3, 0, 5, 3, 4, 2, 5, 2, 1, 2, 4, 3, 5, 0, 7, 0, 5, 5, 0, 0, 4, 1, 7, 1, 0, 0, 1, 3, 5, 5, 6, 2, 2, 1, 7, 5, 2, 5, 0, 0, 4, 2, 0, 1, 0, 8, 0, 1, 7, 4, 5, 5, 5, 3, 2, 1, 1, 4, 0, 0, 7, 4, 7, 4, 5, 1, 0, 7, 3, 4, 3, 8, 4, 4, 4, 2, 0, 5, 1, 2, 5, 4, 2, 0, 4, 2, 2, 4, 2, 3, 0, 7, 0, 5, 0, 6, 1, 0, 5, 7, 4, 2, 4, 0, 4, 2, 4, 0, 4, 1, 6, 0, 1, 4, 0, 1, 5, 0, 6, 5, 0, 2, 6, 1, 0, 1, 8, 0, 2, 7, 2, 6, 7, 2, 5, 4, 1, 7, 2, 5, 0, 4, 2, 6, 2, 7, 8, 0, 0, 5, 6, 2, 6, 0, 4, 1, 4, 7, 2, 4]\n",
            "[0, 3, 5, 2, 3, 1, 1, 1, 4, 3, 3, 2, 7, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 3, 4, 4, 1, 0, 4, 3, 2, 4, 4, 1, 0, 4, 3, 8, 4, 2, 4, 0, 1, 6, 2, 1, 0, 2, 3, 5, 7, 0, 1, 5, 4, 0, 1, 7, 4, 6, 4, 2, 2, 4, 0, 2, 2, 2, 4, 0, 4, 3, 4, 5, 3, 3, 0, 4, 0, 5, 4, 8, 6, 3, 0, 1, 0, 8, 1, 0, 3, 1, 5, 0, 3, 8, 0, 4, 4, 5, 1, 7, 1, 0, 3, 8, 4, 5, 5, 0, 0, 2, 7, 6, 0, 0, 6, 2, 0, 6, 0, 0, 2, 4, 4, 7, 0, 0, 4, 2, 5, 4, 5, 0, 6, 0, 1, 1, 2, 0, 7, 3, 2, 3, 2, 8, 1, 1, 1, 3, 1, 0, 0, 4, 5, 7, 0, 4, 0, 0, 0, 2, 1, 3, 2, 0, 0, 3, 4, 0, 3, 0, 1, 3, 6, 0, 4, 5, 3, 0, 1, 6, 4, 4, 3, 3, 0, 3, 4, 3, 5, 2, 3, 4, 4, 1, 8, 1, 5, 1, 4, 1, 0, 2, 1, 2, 2, 2, 5, 1, 1, 4, 4, 7, 1, 2, 0, 2, 7, 6, 3, 0, 0, 1, 7, 2, 7, 1, 4, 4, 5, 6, 4, 1, 6, 3, 2, 1, 4, 1, 0, 3, 2, 0, 4, 4, 1, 0, 0, 1, 4, 1, 0, 4, 0, 0, 1, 6, 2, 0, 4, 3, 0, 1, 4, 4, 4, 0, 0, 0, 0, 5, 4, 5, 0, 5, 5, 4, 0, 2, 2, 4, 1, 4, 1, 0, 1, 6, 3, 3, 3, 0, 1, 1, 4, 3, 0, 0, 5, 8, 1, 4, 1, 2, 1, 3, 1, 7, 5, 0, 2, 0, 3, 4, 2, 1, 1, 7, 4, 3, 7, 1, 0, 0, 6, 8, 7, 2, 4, 4, 1, 2, 5, 6, 3, 0, 0, 6, 1, 2, 0, 2, 4, 1, 2, 2, 2, 4, 1, 0, 1, 2, 4, 5, 8, 2, 0, 1, 1, 6, 0, 5, 0, 0, 3, 0, 0, 5, 4, 0, 5, 1, 2, 4, 0, 0, 5, 2, 0, 3, 0, 4, 1, 2, 4, 0, 5, 2, 2, 1, 1, 3, 1, 4, 0, 7, 5, 2, 3, 2, 1, 0, 0, 0, 4, 1, 0, 1, 4, 0, 2, 0, 0, 0, 1, 1, 4, 5, 4, 1, 1, 6, 2, 2, 4, 0, 2, 4, 4, 2, 0, 7, 0, 5, 0, 4, 2, 0, 6, 0, 0, 0, 4, 3, 2, 3, 2, 3, 4, 4, 8, 5, 2, 3, 4, 1, 3, 0, 5, 3, 4, 2, 5, 2, 1, 2, 4, 3, 5, 0, 7, 0, 5, 5, 0, 0, 4, 1, 7, 1, 0, 0, 1, 3, 5, 5, 6, 2, 2, 1, 7, 5, 2, 5, 0, 0, 4, 2, 0, 1, 0, 8, 0, 1, 7, 4, 5, 5, 5, 3, 2, 1, 1, 4, 0, 0, 7, 4, 7, 4, 5, 1, 0, 7, 3, 4, 3, 8, 4, 4, 4, 2, 0, 5, 1, 2, 5, 4, 2, 0, 4, 2, 2, 4, 2, 3, 0, 7, 0, 5, 0, 6, 1, 0, 5, 7, 4, 2, 4, 0, 4, 2, 4, 0, 4, 1, 6, 0, 1, 4, 0, 1, 5, 0, 6, 5, 0, 2, 6, 1, 0, 1, 8, 0, 2, 7, 2, 6, 7, 2, 5, 4, 1, 7, 2, 5, 0, 4, 2, 6, 2, 7, 8, 0, 0, 5, 6, 2, 6, 0, 4, 1, 4, 7, 2, 4]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       137\n",
            "           1       1.00      1.00      1.00        98\n",
            "           2       1.00      1.00      1.00        88\n",
            "           3       1.00      1.00      1.00        56\n",
            "           4       1.00      1.00      1.00       105\n",
            "           5       1.00      1.00      1.00        56\n",
            "           6       1.00      1.00      1.00        29\n",
            "           7       1.00      1.00      1.00        32\n",
            "           8       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           1.00       616\n",
            "   macro avg       1.00      1.00      1.00       616\n",
            "weighted avg       1.00      1.00      1.00       616\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Assuming 'val_labels' contains the true labels for the validation set\n",
        "accuracy = accuracy_score(labels, all_preds)\n",
        "f1 = f1_score(labels, all_preds, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score (weighted): {f1:.4f}\")"
      ],
      "metadata": {
        "id": "wvLgUhcfJhi8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}